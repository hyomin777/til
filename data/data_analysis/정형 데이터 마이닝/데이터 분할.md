# 1. 데이터 분할의 이해
## 1. 데이터 분할
- 데이터 마이닝 기법을 적용하기에 앞서 데이터를 훈련용(train), 검정용(validation), 평가용(test)의 세 가지 데이터로 분할한다.
- 훈련용 데이터는 모델을 구축하기 위해 활용되며, 검정용 데이터는 구축된 모델이 적합한지 검증하고 모형의 과대추정 및 과소추정을 방지하기 위해 활용되며, 평가용 데이터는 최종적으로 구축된 모델의 성능을 평가하기 위함이다.
- 분석 모델의 주목적은 한 번도 보지 못한 새로운 데이터를 분류 및 예측하는 것이므로 학습에 전혀 영향을 주지 않은 테스트 데이터로 측정한 성과가 높아야 학습이 적절하게 됐다고 볼 수 있다.

## 2. 과적화(과대적합)과 과소적합
- 과적합의 경우 데이터가 훈련용 데이터에 대하여 너무 많이 설명하려고 하여 모델이 복잡해지고 해석의 어려움이 발생한다. 또한 실제 데이터에 대해 예측력이 떨어지는 문제가 발생한다.
- 과소적합의 경우 데이터 부족 문제로 발생할 수도 있지만 모델이 너무 단순하여 데이터를 충분히 설명하지 못하는 문제를 말한다.

# 2. 데이터 분할을 통한 검증
## 1. 홀드아웃
- 홀드아웃은 가장 보편적인 데이터 분할을 통한 검증 방법이다.
- 홀드아웃은 전체 데이터를 랜덤하게 추출해 학습 데이터와 테스트 데이터로 분리하는 방식이다.
- 검증용 데이터로 하이퍼 파라미터를 튜닝하는 단계까 생략되었으며, 테스트 데이터는 오로지 모델의 성과 평가만을 위해 사용된다.

## 2. K-Fold 교차검증(cross-validation)
- 전체 데이터셋을 k개의 집단으로 구분한 뒤 k-1개를 훈련용 데이터로, 나머지 1개를 평가용 데이터로 사용하여 구축된 k개의 모델을 종합하여 최종 모형을 구축하는 방법이다.
- 모델의 정확도를 향상 시킬 수 있으며, 과적합 및 과소적합을 모두 방지할 수 있다는 장점이 있다.
- 반면, 데이터가 적을 경우에는 과적합 방지가 어려울 수 있으며, k번의 모델 구축을 수행하기 때문에 모델 훈련에 많은 시간을 필요로 한다.

#### LOOCV(Leave-One-Out Cross-Validation)
- 전체 데이터 N개 중에서 N-1개를 훈련용 데이터로, 나머지 1개를 평가용 데이터로 활용하여 N개의 모델을 종합하여 최종 모델을 구축하는 방법이다.
- 전체 데이터 개수인 N번의 훈련을 수행함으로써 수행 속도가 매우 느리다는 것이 단점이다.

## 3. Bootstrap
- 부트스트랩은 표본을 다시 추출하는 방법의 일종이다. 통계학에서 표본을 다시 추출하는 경우는 모델의 신뢰도를 높여 성능을 개선하고자 할 때다. 랜덤하게 반복 추출하여 머신러닝의 모델의 성능 향상을 꾀할 수 있다.
- 부트스트랩은 원본 데이터의 크기만큼 복원추출을 수행하며, 추정의 신뢰성을 평가하는데 사용된다.
- 부트스트랩은 데이터셋의 분포가 고르지 않아 오버샘플링 혹은 언더샘플링과 같은 문제가 있을 때 사용될 수 있으며, 과적합 발생 가능성을 낮출 수 있다.
### 부트스트랩에 한번도 선정되지 않을 확률
- 크기가 n인 데이터셋에서 하나의 데이터를 뽑을 때 특정한 데이터가 뽑힐 확률은 1/n, 뽑히지 않을 확률은 1-1/n이다.
- 크기가 n인 데이터셋에서 부트스트랩을 구성할 때, 특정한 데이터가 한번도 선정되지 않을 확률은 (1-1/n)^n이다.
- 자료 선정을 무한히 반복할 경우 이 근사값은 e^-1에 가까워지며, 이는 약 36.8%에 해당한다.

## 4. 계층별 k-겹 교차 검증(Straified k-fold cross validation)
- 주로 불균형 데이터를 분류하는 문제에서 사용하는 방법으로 작동 방식 k-fold cross validation과 동일하다.
- 예를 들어, 참인 경우가 1,000개, 거짓인 경우가 10개인 데이터 셋의 경우 k-fold cross validation을 사용하면 특정 폴드에는 거짓 데이터가 하나도 포함되지 않을 수도 있다. 계층별 k-겹 교차 검증은 각 폴드가 가지는 레이블의 분포가 유사하도록 폴드를 추출해 교차검증을 실시한다.

## 5. 오버샘플링 & 언더샘플링
- 데이터의 수가 충분하더라도 목표변수의 수가 불균형하면 잘못된 데이터 분할이 수행되어 모델 구축 시 학습이 안되는 경우가 발생할 수 있다.
- 데이터의 목표변수는 균형을 이루었을 때 가장 안정적으로 데이터 분할이 수행 가능하며 목표변수의 다양한 범주에 대해서 학습이 가능하다.
- 특정 범주가 많은 데이터를 다른 범주와 균형을 맞추도록 데이터 셋을 축소시키는 작업을 언더샘플링이라 하며, 특정 범주가 적은 데이터를 데이터 셋의 크기를 확장시키는 작업을 오버샘플링이라 한다.