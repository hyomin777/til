# 1. 베이즈 이론(Bayes Theorem)
## 1. 베이즈 이론(베이지안 확률)
- 베이즈 이론은 확률을 해석하는 이론이다. 통계학에서 확률은 크게 빈도 확률과 베이지안 확률로 구분할 수 있다. 이 둘의 계산 방법은 크게 다르지 않지만 해석하는 방법에서 차이가 나는데, 빈도 확률은 객관적으로 확률을 해석하고 베이지안 확률은 주관적으로 확률을 해석한다.
- 빈도 확률이란 사건이 발생한 횟수의 장기적인 비율을 의미한다. 빈도 확률은 근본적으로 반복되는 어떤 사건의 빈도를 다루는 것으로, 모집단으로부터 반복적으로 표본을 추출했을 때 추출된 표본이 사건 A에 포함되는 경향을 사건 A의 확률이라 한다.
- 이에 반해 베이지안 확률은 사전확률과 우도확률을 통해 사후확률을 추정하는 정리로, 데이터를 통해 확률을 추정할 때 현재 관측된 데이터의 빈도만으로 분석하는 것이 아니라 분석자의 사전지식(이미 알려진 사실 혹은 분석자의 주관)까지 포함해 분석하는 방법이다.
- 베이즈 정리에서 확률은 '주장 혹은 믿음의 신뢰도'로 나타난다. 통계학 책에 따라서는 베이즈 이론을 '두 확률변수의 사전 확률과 사후 확률 사이의 관계를 나타내는 정리'라고 정의하기도 한다.
$$
P(H|E) = (\frac{P(E|H)P(H)}{P(E)})
$$

# 2. 나이브 베이즈 분류
## 1. 나이브 베이즈 개념
- 나이브 베이즈 분류 모델은 베이즈 정리를 기반으로 한 지도학습 모델로, 스팸 메일 필터링, 텍스트 분류 등에 사용할 수 있다.
- 나이브 베이즈는 데이터의 모든 특징 변수가 서로 동등하고 독립적이라는 가정하에 분류를 실행한다. 질환 유무를 분류할 수 있게 해주는 특성들은 나이브 베이즈에서 서로 연관성이 없고, 각각의 특성이 질환의 유무에 독립적으로 기여하는 것으로 간주한다.

## 2. 나이브 베이즈 알고리즘
- 나이브 베이즈 알고리즘은 이진 분류 데이터가 주어졌을 때 베이즈 이론을 통해 범주 a, b가 될 확률을 구하고, 더 큰 확률값이 나오는 범주에 데이터를 할당하는 알고리즘이다. 범주 a, b에 속할 확률은 다음과 같다.
    - 범주 a에 속할 확률 = $P(a|E)=(\frac{P(E|a)P(a)}{P(E)})$

    ## 2. 나이브 베이즈 알고리즘
- 나이브 베이즈 알고리즘은 이진 분류 데이터가 주어졌을 때 베이즈 이론을 통해 범주 a, b가 될 확률을 구하고, 더 큰 확률값이 나오는 범주에 데이터를 할당하는 알고리즘이다. 범주 a, b에 속할 확률은 다음과 같다.
    - 범주 a에 속할 확률 = 
$ P(a|E) = (\frac{P(E|a)p(a)}{P(E)}) $
    - 범주 b에 속할 확률 =
$ P(a|E) = (\frac{P(E|b)p(b)}{P(E)}) $

- P(a)와 P(b)는 사전확률로, 범주 a와 b에 해당하는 레코드를 전체 레코드로 나눈 비율을 의미한다.
- P(E)는 두 수식에 겹쳐 나오므로 생략하고 계산할 수 있으며, 데이터가 변수 v_1, v_2, v_3로 구성되어 있다면 다음과 같이 표현할 수 있다.
$$
P(v_1, v_2, v_3|E) = P(a) * P(v_1|a) * P(v_2|a) * P(v_3|a)
$$