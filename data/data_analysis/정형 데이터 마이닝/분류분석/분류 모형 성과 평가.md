# 1. 성과 평가 개요
- 여러 분류 기법들을 적용해보고 여러 모델 중 가장 예측력이 좋은 모델을 최종 모델로 선정하기 위해서는 평가 기준이 필요하다.
- 모형 평가의 기준으로는 다른 데이터에서도 안정적으로 적용이 가능한지 판단하는 일반화, 모형의 계산 양에 비한 모형의 성능을 고려하는 효율성, 구축된 모형의 분류 정확성 등이 있다.

# 2. 오분류표와 평가 지표
- 분류 분석 성과 평가는 간단히 말해서 분류 분석 모형이 내놓은 답과 실제 정답이 어느 정도 일치하는지를 판단하는 것이다.
- 일반적으로 정답과 예측값은 True와 False, 0과 1, 양성과 음성, Yes와 No 등의 이진 분류 클래스 레이블을 갖는다.
- 분류 분석 후 예측한 값과 실제 값의 차이를 교차표(Cross Table) 형태로 정리한 것을 오분류표 혹은 Confusion Matrix(혼동행렬)라고 부른다.
- 오분류표는 실제값과 예측치의 값에 대한 옳고 그름을 표로 나타낸 것으로, 분류오차의 정확한 추정치를 얻기 위해서 평가용 데이터로부터 계산되어 얻은 표다. 훈련용 데이터를 활용한 오분류표는 과적합의 위험성이 존재하기 때문이다. 
-----
- TP(True Positive): 예측한 값이 Positive이고 실제 값도 Positive인 경우
- FP(False Positive): 예측한 값이 Positive이고 실제 값은 Negative인 경우
- TN(True Negative): 예측한 값이 Negative이고 실제 값도 Negative인 경우
- FN(False Negative): 예측한 값이 Negative이고 실제 값은 Positive인 경우

### 정확도(Accuracy)
- 전체 관측치 중 올바르게 예측한 비율
$$
\frac{TP+TN}{TP+FN+FP+TN}
$$

### 오분류율(Erro Rate)
- 전체 관측치 중 잘못 예측한 비율
$$
\frac{FP+FN}{TP+FN+FP+TN}
$$

### 재현율(Recall)
- 실제 True 중 올바르게 True를 찾아낸 비율
- 민감도와 동일한 지표로 모형의 완전성을 평가하는 지표
$$
\frac{TP}{TP+FN}
$$

### 특이도(Specificity)
- 실제 False 중 올바르게 False를 찾아낸 비율
$$
\frac{TN}{FP+TN}
$$

### 정밀도(Precision)
- 예측 True 중 올바르게 True를 찾아낸 비율
$$
\frac{TP}{TP+FP}
$$

### F1 Score
- 정밀도와 재현율의 조화평균 값으로 정밀도의 재현율은 높은 확률로 음의 상관관계를 가질 수 있는 효과를 보정하기 위한 지표로 값이 높을수록 좋다.
$$
F1\,score = \frac{2*Precision*Recall}{Precision+Recall}
$$

### 거짓 긍정률(FPR: False Positive Rate)
- 실제 Negative인 값 중 Positive로 잘못 분류한 비율
$$
1-\frac{TN}{FP+TN} = \frac{FP}{FP+TN}
$$

### F-Beta Score
- F1 Score는 재현율과 정밀도의 조화평균으로 두 값의 가중치가 동일한 경우 활용 가능하다. 그러나 병원과 같이 암환자가 아닌 사람을 암환자로 판단하는 경우(정밀도)보다 암환자인 사람을 암환자가 아니라고 판단하는 경우(재현율)를 더 위험하다고 보기 때문에 Beta 값을 조정하여 재현율에 높은 가중치를 줄 수 있다.
$$
F_\beta = (1+\beta^2)\frac{precision*recall}{(\beta^2*precision)+recall}
$$
- $\beta=1$: 재현율과 정밀도에 동일한 가중치(F1-Scroe 값과 동일)
- $\beta>1$: 재현율에 높은 가중치, 정밀도에 낮은 가중치
- $0<\beta<1$: 재현율에 낮은 가중치, ,정밀도에 높은 가중치

# 3. ROC 커브
- ROC 커브(Receiver Operating Characteristic Curve)는 분류 분석 모형의 평가를 쉽게 비교할 수 있도록 시각화한 그래프다.
- x축은 FPR(1-특이도) 값을, y축은 TPR(민감도) 값을 갖는 그래프다. 이진 분류(0 또는 1) 모형의 성능을 평가하기 위해 사용된다.
- ROC 커브의 아래 면적을 나타내는 AUROC(Area Under ROC)의 값이 1에 가까울수록 모형의 성능이 우수하며 0.5에 가까울수록 무작위로 예측하는 랜덤 모델에 가까운 좋지 못한 모형이다.