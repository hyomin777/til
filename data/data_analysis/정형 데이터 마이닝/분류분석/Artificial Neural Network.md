# 1. 인공신경망 개요
- 인공신경망은 인간의 뇌를 모방하여 만들어진 학습 및 추론 모형이다.
- 인간의 뇌는 여러 시냅스의 결합으로 신호를 전달받아 일정 기준치를 초과할 때 뉴런이 활성화되고 출력 신호를 내보낸다.
- 뉴런과 뉴런 사이는 시냅스로 연결되어 있는데, 입력신호가 다른 뉴런으로 전달되기 위해서는 신호의 강도가 일정 기준치를 초과해야 한다. 인공신경망 분석은 이러한 뇌의 구조를 수학적으로 단순화해 모델링한 것이다.
- 인공신경망 분석에서 값이 입력되면 개별 신호의 정도에 따라 값이 가중된다. 가중된 값에 편향(bias)이라는 상수를 더한 후 활성함수를 거치면 인공신경망의 출력값이 생성된다.
- 인공신경망의 등장과 발전으로 인하여 머신러닝을 넘어서서 딥러닝이 등장했으며, 현재의 CNN, RNN 등과 같은 다양한 알고리즘의 기반을 마련했다.

## 인공신경망 분석의 장단점
- 장점
    - 잡음에 민감하게 반응하지 않는다.
    - 비선형적인 문제를 분석하는데 유용하다.
    - 패턴인식, 분류, 예측 등의 문제에 효과적이다.
    - 스스로 가중치를 학습하므로 다양하고 많은 데이터에 효과적이다.
- 단점
    - 모형이 복잡할 경우 학습에 오랜 시간이 소요된다.
    - 초기 가중치에 따라 전역해가 아닌 지역해로 수렴할 수 있다.
    - 추정한 가중치의 신뢰도가 낮다.
    - 결과에 대한 해석이 쉽지 않다.
    - 은닉층의 수와 은닉 노드의 수를 결정하기 어렵다.

# 2. 인공신경망의 알고리즘
## 1. 활성함수
- 인공신경망은 노드에 입력되는 값을 바로 다음 노드로 전달하지 않고 비선형 함수에 통과시킨 후 전달한다. 이때 사용되는 함수를 활성함수라고 한다.
- 어떤 활성함수를 사용하느냐에 따라 그 출력값이 달라지므로 적절한 활성함수를 사용하는 것이 중요하다.
- 대표적인 활성함수로는 Sigmoid 함수, Softmax 함수, ReLU 함수 등이 있다.

### Step 함수
- 기본적인 활성함수로, 0 또는 1을 반환하는 이진형 함수다.
- 입력값이 0에서 미분되지 않아 역전파 알고리즘에 활용할 수 없는 단점이 있다.
$$
S(x) = 
\begin{cases}
0,\, x<0 \\
1,\, x=>0
\end{cases}
$$

### Sigmoid 함수
- 로지스틱 회귀분석의 확률값을 구하기 위한 계산 식과 유사하며, 0과 1사이의 값을 반환한다.
- 입력값의 절댓값이 커질수록 미분값(접선의 기울기)이 0에 가까워지므로 기울기 소실 문제가 발생할 수 있다.
$$
S(x)=\frac{1}{1+exp(-x)}
$$

### Sign 함수
- 기본적인 활성함수로, -1 또는 1을 반환하는 이진형 함수다.
- 입력값이 0에서 미분되지 않아 역전파 알고리즘에 활용할 수 없는 단점이 있다.
$$
S(x) = 
\begin{cases}
-1,\, x<0 \\
1,\, x=>0
\end{cases}
$$

### tanh 함수
- 확장된 형태의 시그모이드 함수로, 중심값은 0이며, -1과 1사이의 값을 출력한다.
- 시그모이드와 유사한 그래프를 가지므로 기울기 소실 문제가 발생할 수 있는 단점이 있다.
$$
S(x) = \frac{exp(x)-exp(-x)}{exp(x)+exp(-x)}
$$

### ReLU 함수
- 최근 딥러닝에서 가장 많이 사용되는 함수로, 입력값과 0 중에서 큰 값을 반환한다.
- Sigmoid 함수와 tanh 함수 사용 시 기울기 소실 문제가 예상된다면 ReLU 함수를 사용하여 해당 문제를 방지할 수 있다.
$$
S(x) = 
\begin{cases}
0,\, x <= 0 \\
x,\, x > 0
\end{cases}
$$

### Softmax 함수
- 표준화지수 함수라고도 불리며, 출력값이 다범주인 경우에 사용된다.
- 로지스틱 회귀분석과 마찬가지로 각 범주에 속할 확률값을 반환한다.
$$
S(x_i) = \frac{exp(x_n)}{\sum^k_{i=1}exp(x_i)},\, for \; n \; in \; 1, \; ..., \; k
$$

## 2. 인공신경망 계층 구조
- 하나의 인공신경망은 데이터를 입력하는 입력층, 데이터를 출력하는 출력층을 갖고 있는 단층신경망과 입력층과 출력층 사이에 보이지 않는 다수의 은닉층을 가지고 있을 수 있는 다층신경망으로 구분할 수 있다. 은닉층이 존재하지 않는 단층신경망은 한계점이 있기에 일반적인 인공신경망은 다층신경망을 의미한다.
- 입력층은 데이터를 입력받아 시스템으로 전송하는 역할을 한다. 은닉층은 신경망 외부에서는 은닉층의 노드에 직접 접근할 수 없도록 숨겨진, 말 그대로 은닉한 층이다. 은닉층은 입력층으로부터 값을 전달받아 가중치를 계산한 후 활성함수에 적용하여 결과를 산출하고 이를 출력층으로 보낸다. 출력층은 학습된 데이터가 포함된 층으로, 활성함수의 결과를 담고 있는 노드로 구성된다. 출력층의 노드수는 출력 범주의 수로 결정된다. 분류 모델일 경우 출력층의 노드는 각 라벨의 확률을 포함한다.

## 3. 인공신경망 학습(역전파 알고리즘)
- 인공신경망은 여러 개의 퍼셉트론으로 구성되어 있기 때문에 각 퍼셉트론이 보유한 여러 개의 가중치 $w_i$ 값의 결정이 중요하다. 인공신경망은 지도학습의 한 종류로 입력층(독립변수)과 출력층(반응변수)의 데이터에 따른 이상적인 가중치 $w_i$ 값을 결정해야 한다.
- 가중치 값의 결정은 입력층에서 출력층으로 찾아 나가는 순전파 알고리즘을 먼저 활용한다. 이때 발생한 오차들을 줄이고자 출력층에서 입력층 방향으로 거꾸로 찾아 나가는 역전파 알고리즘을 활용하여 가중치 값들을 새롭게 조정한다. 훈련용 데이터의 자료들이 순차적으로 입력될 때 마다 가중치가 새롭게 조정되는 것을 인공신경망이 학습한다고 표현한다. 이때 전체 자료들에 의하여 학습이 한 번 되는 것을 1 epoch 이라 하면 일정 수의 epoch에 도달하거나 혹은 원하는 수준의 정확도를 얻을 때 까지 위 작업을 반복한다.

# 3. 인공신경망의 종류
## 1. 단층 퍼셉트론(단층 신경망)
- 입력층이 은닉층을 거치지 않고 바로 출력층과 연결된다.
- 퍼셉트론은 여러 개의 개별 입력 데이터를 받아 하나의 입력 데이터로 가공하여 활성함수에 의하여 출력값을 결정한다. 퍼셉트론의 출력값은 또 다른 퍼셉트론의 입력 데이터가 된다.
- 단층 퍼셉트론은 다수의 입력값을 받아 하나의 출력값을 출력하는데, 이 출력값이 정해진 임곗값을 넘었을 경우 1을 출력하고 넘지 못했을 경우 0을 출력한다.

## 2. 다층 퍼셉트론(다층 신경망)
- 하나의 퍼셉트론은 데이터를 입력하는 입력층, 데이터를 출력하는 출력층을 갖고 있는 단층 퍼셉트론과 입력층과 출력층 사이에 보이지 않는 다수의 은닉층을 가지고 있을 수 있는 다층 퍼셉트론으로 구분할 수 있다.
- 은닉층이 존재하지 않는 단층 퍼셉트론은 한계점이 있기에 일반적으로 인공신경망을 부를 때 다층 퍼셉트론을 의미한다.
- 다층 퍼셉트론은 단층 퍼셉트론보다 학습하기가 어려우며 은닉층의 노드의 수가 너무 적으면 복잡한 의사결정 경계를 구축할 수 없고, 은닉층의 노드의 수가 너무 많으면 일반화가 어렵기 때문에 과적합 문제가 발생하며, 너무 적은 은닉층과 은닉노드는 과소적합 문제가 발생하기 때문에 적절한 노드의 수를 찾는 것이 중요하다.

## 다양한 인공신경망 구조
### RNN
- 순환 신경망으로 입력층의 데이터는 은닉층을 통해 출력층으로 가지만 은닉층의 결괏값이 다음 입력 데이터가 입력될 때 자기 자신에게 영향을 주는 신경망이다.
- 언어 모델링, 음성 인식 등에 활용될 수 있다. 그러나 시간적으로 오래된 데이터에 대한 문맥 처리가 어려운 것이 단점이다.

### CNN
- 합성곱 신경망으로 이미지 분류 및 다중객체탐지(Multi Object Detection)에 뛰어난 성능을 보인다.
- 합성곱과 풀링의 두 개의 작업으로 구성되어 있다.

### LSTM
- 장단기 메모리라고 하며, RNN의 한계를 극복하기 위해 나온 인공신경망 모델이다.
- 오래된 데이터는 버리고, 가장 최근의 데이터를 더욱 오래 보존하려는 것이 특징이다.

### YOLO
- 이미지 속에서 물체를 탐지하는 알고리즘으로, CNN과 목적은 유사하지만 다른 알고리즘을 갖는다.
- 한 장의 이미지를 수십 개의 박스로 나누어 각 박스에 대해 가장 확률이 높은 객체를 탐지한다.
- You Only Look Once의 약자로, 이미지 전체를 한 번만 보기 때문에 빠른 속도를 보여준다.

### GAN
- 생산적 적대 신경망으로, 위조지폐범의 위조지폐 생산과 경찰(분류 모형)의 지폐 판별 과정을 반복하면서 학습할 경우 위조지폐범이 진짜에 가까운 위조지폐를 생산할 수 있는 것처럼 분류 모형으로부터 최적의 결과를 얻을 수 있도록 유도하는 학습이다.
- 대표적인 사례로 페이스북의 딥 페이스가 있다.