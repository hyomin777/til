# 1. ANOVA(분산분석)
## 1. 분산분석 개요
- 분산분석은 세 개 이상의 모집단이 있을 경우에 여러 집단 사이의 평균을 비교하는 검정 방법이다.
- 분산분석의 귀무가설은 항상 '$H_0$: 모든 집단 간 평균은 같다'이다.
- 분산분석을 수행하기 위해서는 아래의 세 가지 가정사항을 필요로 한다.
  1. 정규성: 각 집단의 표본들은 정규분포를 따라야 한다.
  2. 등분산성: 각 집단은 동일한 분산을 가져야 한다.
  3. 독립성: 각 집단은 서로에게 영향을 주지 않는다.

- 분산분석은 귀무가설을 기각할 경우 어느 집단 간 평균이 같은지, 혹은 어느 집단 간의 평균이 얼마나 다른지 알 수 없다.
- 그래서 분산분석의 귀무가설을 기각했을 경우 어느 집단 간에 차이를 보이는지 알기 위한 사후검정 방법으로 Scheffe, Tukey, Duncan, Fisher's LSD, Dunnett, Bonferroni 등의 방법을 사용한다.
- 분산분석의 독립변수는 범주형 데이터여야 하고, 종속변수는 연속형이여야 한다.
- 분산분석에는 '(집단 간 분산) / (집단 내 분산)'으로 계산되는 F-value가 사용된다.
- 평균을 비교하는 분산분석에 '분산'의 개념을 사용하는 이유는 집단 간 평균의 분산이 클수록 각 집단의 평균은 서로 멀리 떨어져 있기 때문이다. 그래서 집단 간 차이를 비교하기 쉬워진다.

## 2. one-way Anova(일원분산분석)
- 셋 이상의 집단 간 평균을 비교하는 상황에서 하나의 집단에 속하는 독립변수와 종속변수 모두 한 개일 때 사용한다.
- 예컨대 연령대별(청소년, 성인, 노인) 유튜브 시청 시간의 차이가 있는지 알아보고 싶다고 가정해보자.
  - 독립변수는 연령별 집단(청소년, 성인, 노인)이다.
  - 종속변수는 유튜브 시청 시간이다.
  - 셋 이상의 집단이지만 독립변수는 '연령별 집단'하나의 종류로 봐야한다. 하나의 독립변수가 각각 종속변수에 영향을 끼치기 때문이다. 
- 분산분석표
  - 요인(Source)
    - 분석의 원인 또는 요인을 나타낸다.
    - 처리(SSR, Treatment): 집단 간 변동(집단 간 평균 차이)을 측정
    - 잔차(SSE, Error): 집단 내 변동(오차, 무작위 요인)을 측정
    - 계(SST, Total): 총 변동(전체 데이터의 변동량)을 측정하며, 이는 처리와 잔차의 합으로 계산됨
  - 제곱합(Sum of Squares)
    - 각 요인의 변동량을 측정
    - SSR(Sum of Squares for Regression): 처리 요인에 의한 변동량
    - SSE(Sum of Squares for Error): 잔차, 즉 처리 외에 발생한 변동량
    - SST(Total Sum of Squares): 전체 데이터의 변동량으로, SST = SSR + SSE
  - 자유도(Degrees of Freedom)
    - 각 변동량을 계산할 때의 자유도를 나타낸다.
    - 처리의 자유도(a): 집단 수 - 1
    - 잔차의 자유도(b): 전체 데이터 수 - 집단 수
    - 전체 자유도(a + b): 전체 데이터 수 - 1
  - 제곱평균(Mean Square)
    - 각 변동량을 자유도로 나누어 계산한다.
    - MSR(Mean Square for Regression): MSR = SSR / a, 처리 요인의 평균 변동량
    - MSE(Mean Square for Error): MSE = SSE / b, 잔차 요인의 평균 변동량
  - F비(F-statistic)
    - 처리 요인의 변동량과 잔차 요인의 변동량의 비율로, 분산분석의 핵심 검정통계량
    - F = MSR / MSE
    - F값이 클수록 집단 간 평균의 차이가 통계적으로 유의하다고 판단할 가능성이 높아진다.

## 3. 일원분산분석 R 실습
- 신형 핸드폰 A, B, C의 속도 차이가 있는지 여부
- 귀무가설: A, B, C라는 세 대의 신형 핸드폰 간의 속도 차이는 없다.
- 대립가설: 집단 간 평균의 차이가 존재한다.
```
> phoneSpeed <- runif(45, min = 75, max = 100)
> telecom <- rep(c('A', 'B', 'C'), 15)
> phoneData <- data.frame(phoneSpeed, telecom)
> result <- aov(data = phoneData, phoneSpeed ~ telecom)
> summary(result)
            Df Sum Sq Mean Sq F value Pr(>F)
telecom      2     34   17.02    0.37  0.693
Residuals   42   1930   45.95
```
- F=0.37 (집단 간 변동이 집단 내 변동에 비해 매우 작음).
- p-value: p=0.693는 0.05보다 크므로 귀무가설을 기각할 수 없다.
- 따라서, 핸드폰 A, B, C 간의 속도 차이는 통계적으로 유의미하지 않다고 결론 내릴 수 있다.

## 4. two-way Anova(이원분산분석)
- 일원분산분석 수행 시 독립변수의 수가 두 개 이상일 때 사용한다.
  - ex. 성별, 연령별 유튜브 시청 시간 차이를 알아보고 싶은 경우
- 이원분산분석은 독립변수 간 교호작용이 있다고 판단될 때는 '반복이 있는 실험'을 하고, 교호작용이 없다고 판단될 때, 즉 두 독립변수가 독립인 경우에는 '반복이 없는 실험'을 한다.
- 이원분산분석은 독립변수 간의 교호작용을 먼저 살펴보고 두 가지로 나누어서 실험해야 한다.
  - 교호작용: 독립변수끼리 서로 영향을 미치는 경우
- 예시를 들어보면, '여성'이라는 독립변수의 경우 '노인'변수와는 교호작용이 미약할 수도 있겠지만, '여성'이라는 독립변수가 '청소년'과 만나면 서로 강한 교호작용이 있을 수 있다. 그래서 이원분산분석을 수행할 때 독립변수 간 교호작용을 먼저 살펴보고 두 가지로 나누어서 수행하는 것 이다.
- 만약 집단 간의 평균 차이를 검증할 때 종속변수가 2개 이상이라면 '다변량분산분석(Manova)'을 수행한다. 이를 '다원분산분석'이라 부르기도 한다.