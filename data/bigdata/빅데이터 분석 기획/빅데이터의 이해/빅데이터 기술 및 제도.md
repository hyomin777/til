# 1. 빅데이터 플랫폼
빅데이터 플랫폼은 빅데이터 수집부터 저장, 처리, 분석 등 전 과정을 통합적으로 제공하여 그 기술들을 잘 사용할 수 있도록 준비된 환경이다.
- 빅데이터를 분석 또는 활용하는데 필수적인 것으로, 빅데이터 기술의 집약체

## 1. 빅데이터 플랫폼의 등장배경
### 1. 비즈니스 요구사항 변화
- 빠른 의사결정 속도보다 장기적이고 전략적인 접근이 필요하다.
- 초저가의 대규모 프로세싱과 클라우트 컴퓨팅 기반의 분석 환경이 등장하였다.
- 새로운 형태의 비즈니스 질문과 통찰이 요구되고 있다.

### 2. 데이터 규모의 처리 복잡도 증가
- 데이터 범위와 기간이 확정되어 처리할 데이터 규모와 내용이 방대해졌다.
- 정보의 수집 및 분석이 일시적이지 않고 장기간에 걸쳐 수행되어야 한다.
- 다양한 경로를 통해 다양한 형태의 데이터 수집과 복잡한 로직을 이용한 대용량 처리가 필요하다.
- 분산 처리가 불가피하며 이를 제어할 수 있는 고도의 기술이 필요하다.

### 3. 데이터 구조의 변화와 신속성 요구
- SNS 데이터나 로그 파일, 스트림 데이터 등 비정형 데이터의 비중과 실시간 처리에 대한 요구가 높아지고 있다.
- 약한 관계형 스키마나 반정형 데이터와 같은 정형적이지 않은 데이터가 증가하고 있다.
- 데이터 발생 속도가 빨라져 빠른 수집과 가공 및 분석 등 처리가 요구된다.

### 4. 데이터 분석 유연성 증대
- 기존의 통계적 분석방법과 같이 정해진 절차와 과정을 따르지 않아도 분석 목적에 맞게 유연한 분석이 가능하게 되었다.
- 인공지능 기술의 발전으로 다양한 방법론을 통해 텍스트, 음성, 이미지, 동영상 등 다양한 요소들의 분석이 가능하게 되었다.

## 2. 빅데이터 플랫폼의 기능
빅데이터를 처리하는 과정에서 부하 발생은 불가피하며, 빅데이터 플랫폼은 이러한 부하들을 기술적인 요인들을 결합하여 해소한다.

### 1. 컴퓨팅 부하 발생
- 빅데이터를 처리하고자 할 때 연산과정에서 CPU, GPU, 메모리 등을 사용하며 부하가 발생한다.
- 빅데이터 플랫폼을 통한 CPU 성능 향상 및 클러스터(Cluster)에서의 효과적인 자원 할당을 통해 부하를 제어할 수 있다.
### 2. 저장 부하 발생
- 빅데이터 처리 과정의 입력 데이터, 중간 가공 데이터, 출력 데이터 등 여러 단계에서 부하가 발생한다.
- 빅데이터 플랫폼을 통한 파일 시스템 개선, 메모리와 파일 시스템의 효과적인 사용 및 데이터베이스 성능 향상으로 제어할 수 있다.
### 3. 네트워크 부하 발생
- 빅데이터를 처리하는 과정에서 분산처리를 하고자 할 때 노드(Node) 간의 통신 과정에서 부하가 발생한다.
- 빅데이터 플랫폼을 통한 대역폭의 효과적 분배 및 네트워크상에서 최단거리에 위치한 노드를 탐색하여 제어할 수 있다.

## 3. 빅데이터 플랫폼의 조건
빅데이터 플랫폼은 서비스 사용자와 제공자 어느 한쪽에 치우쳐서는 안되며 모두가 만족할 수 있는 환경을 제공하여야 한다.

### 1. 서비스 사용자 측면에서의 체크리스트
- 주어진 문제를 해결하기에 충분한 요소들을 제공하는 환경인가?
- 편리한 사용자 인터페이스(UI: User Interface)를 제공하는가?

### 2. 서비스 제공자 측면에서의 체크리스트
- 성능적인 문제가 발생하지 않도록 충분한 관리 기능을 제공하는가?
- 사용자 접속 및 인증을 관리할 수 있는 기능을 제공하는가?
- 효율적인 운영을 위한 자원 관리 기능을 제공하는가?
- 서비스 품질 관리를 위한 각종 지표들을 충분히 제공하는가?
- 안전한 서비스 제공을 위한 보안적인 요소들을 갖추고 있는가?
- 플랫폼 도입을 통해 비용 절감을 이룰 수 있는가?

## 4. 빅데이터 플랫폼의 구조
빅데이터 플랫폼은 위에서부터 소프트웨어 계층, 플랫폼 계층, 인프라스트럭처 계층의 3계층으로 구성되어 있다.

### 1. 소프트웨어 계층
빅데이터 애플리케이션을 구성하며 데이터 처리 및 분석과 이를 위한 데이터 수집, 정제를 한다.

- 데이터 처리 및 분석 엔진: 데이터를 처리하고 분석한다.
    - 데이터 처리 및 분석: 서비스에 따른 데이터 처리 및 분석을 수행한다.
    - 처리 및 분석 워크플로우 구성: 데이터 처리 및 분석을 위한 워크플로우를 구성한다.
    - 데이터 표현: 데이터 처리 및 분석한 결과를 표현한다.
- 데이터 수집 및 정제 모듈: 빅데이터 분석 엔진을 위한 데이터를 수집하고 정제한다.
    - 데이터 추출: 원천 데이터에서 데이터를 추출한다.
    - 데이터 변환: 원천 데이터에서 추출한 데이터를 변환하고 균질화 및 정제한다.
    - 데이터 적재: 변환된 데이터를 데이터 웨어하우스로 적재한다.
- 서비스 관리 모듈: 소프트웨어 계층에서 제공하는 서비스를 관리한다.
- 사용자 관리 모듈: 사용자를 관리한다.
    - 인증 및 접속 관리: 사용자별 인등과 접속 관리를 한다.
    - 사용자 서비스 관리: 사용자별 서비스를 관리한다.
    - SLA 관리: 사용자별 서비스 수준 협약(Service Level Agreement)을 관리한다.
- 모니터링 모듈: 플랫폼 및 인프라스트럭처 서비스 사용성과 성능을 모니터링 한다.
- 보안 모듈: 소프트웨어 계층의 보안을 관리한다.

### 2. 플랫폼 계층
빅데이터 애플리케이션을 실행하기 위한 플랫폼을 제공하며, 작업 스케줄링이나 데이터 및 자원 할당과 관리, 프로파일링 등을 수행한다.

- 사용자 요청 파싱: 사용자가 요청한 내용을 파싱한다.
- 작업 스케줄링 모듈: 사용자 애플리케이션 실행 작업을 스케줄링한다.
- 데이터 및 자원 할당 모듈: 사용자 애플리케이션을 실행하는 데이터와 자원을 할당한다.
    - 초기 데이터 할당: 사용자 애플리케이션을 실행하는 사용자의 데이터를 초기 할당한다.
    - 데이터 재할당 및 복제: 동적인 상황을 고려하여 데이터를 재할당 및 복제한다.
    - 초기 자원 할당: 사용자 애플리케이션을 실행하는 인프라스트럭처의 자원을 초기 할당한다.
    - 자원 재할당 및 스케일링: 동적인 상황을 고려하여 자원을 재할당 및 스케일링한다.
- 프로파일링 모듈: 자원 및 애플리케이션을 프로파일링 또는 시뮬레이션한다.
    - 자원 프로파일링: 인프라스트럭처 자원을 할당하는 인프라스트럭처 자원을 프로파일링한다.
    - 애플리케이션 프로파일링: 인프라스트럭처 자원을 할당하는 사용자 애플리케이션을 프로파일링한다.
    - 애플리케이션 시뮬레이션: 인프라스트럭처 자원 선택 및 구성을 하는 사용자 애플리케이션을 시뮬레이션한다.
- 데이터 관리 모듈: 사용자 데이터를 관리한다.
- 자원 관리 모듈: 인프라스트럭처 자원을 관리한다.
- 서비스 관리 모듈: 플랫폼 계층에서 제공하는 서비스를 관리한다.
- 사용자 관리 모듈: 사용자를 관리한다.
    - 인증 및 접속 관리: 사용자별 인증과 접속 관리를 한다.
    - 사용자 서비스 관리: 사용자별 서비스를 관리한다.
    - SLA 관리: 사용자별 서비스 수준 협약(SLA)을 관리한다.
- 모니터링 모듈: 인프라스트럭처 서비스 가용성과 성능을 모니터링한다.
- 보안 모듈: 소프트웨어 계층의 보안을 관리한다.

### 3. 인프라스트럭처 계층
자원 배치와 스토리지 관리, 노드 및 네트워크 관리 등을 통해 빅데이터 처리와 분석에 필요한 자원을 제공한다.

- 사용자 요청 파싱: 사용자가 요청한 내용을 파싱한다.
- 자원 배치 모듈: 사용자에게 제공할 자원을 배치한다.
    - 초기 자원 배치: 사용자에게 제공하는 자원을 초기 배치한다.
    - 자원 재배치 및 스케일링: 동적인 상황을 고려하여 자원을 재배치 및 스케일링한다.
- 노드 관리 모듈: 인프라스트럭처 내의 노드를 관리한다.
- 데이터 관리 모듈: 인프라스트럭처 내의 스토리지를 관리한다.
- 네트워크 관리 모듈: 인프라스트럭처 내외의 네트워크를 관리한다.
- 서비스 관리 모듈: 인프라스트럭처 계층에서 제공하는 서비스를 관리한다.
- 사용자 관리 모듈: 사용자를 관리한다.
    - 인증 및 접속 관리: 사용자별 인증과 접속 관리를 한다.
    - 사용자 서비스 관리: 사용자별 서비스를 관리한다.
    - SLA 관리: 사용자별 서비스 수준 협약(SAL)을 관리한다.
- 모니터링 모듈: 서비스를 모니터링 한다.
    - 서비스 모니터링: 서비스 가용성과 성능을 모니터링 한다.
    - 자원 모니터링: 노드, 스토리지, 네트워크 등 자원 가용성과 성능을 모니터링 한다.
- 보안 모듈: 소프트웨어 계층의 보안을 관리한다.

# 2. 빅데이터 처리기술
## 1. 빅데이터 처리과정과 요소기술
- 빅데이터의 처리과정: 데이터(생성) - 수집 -저장(공유) - 처리 - 분석 - 시각화

- 생성
    - 데이터베이스나 파일 관리 시스템과 같은 내부 데이터가 있다.
    - 인터넷으로 연결된 외부로부터 생성된 파일이나 데이터가 있다.

- 수집
    - 크롤링을 통해 데이터 원천으로부터 데이터를 검색하여 수집한다.
    - ETL을 통해 소스 데이터로부터 추출하고, 변환하여, 적재한다.
    - 단순한 수집이 아니라 검색 및 수집, 변환 과정을 모두 포함한다.
    - 로그 수집기나, 센서 네트워크 및 Open API 등을 활용할 수 있다.

- 저장(공유)
    - 저렴한 비용으로 데이터를 쉽고 빠르게 많이 저장한다.
    - 정형 데이터뿐만 아니라 반정형, 비정형 데이터도 포함한다.
    - 병렬 DBMS나 하둡(Hadoop), NoSQL 등 다양한 기술을 사용할 수 있다.
    - 시스템 간의 데이터를 서로 공유할 수 있다.

- 처리
    - 데이터를 효과적으로 처리하는 기술이 필요한 단계이다.
    - 분산 병렬 및 인메모리(In-memory) 방식으로 실시간 처리한다.
    - 대표적으로 하둡(Hadoop)의 맵리듀스(MapReduce)를 활용할 수 있다.

- 분석
    - 데이터를 신속하고 정확하게 분석하여 비즈니스에 기여한다.
    - 특정 분야 및 목적의 특성에 맞는 분석 기법 선택이 중요하다.
    - 통계분석, 데이터 마이닝, 텍스트 마이닝, 기계학습 방법 등이 있다.

- 시각화
    - 빅데이터 처리 및 분석 결과를 사용자에게 보여주는 기술이다.
    - 다양한 수치나 관계 등을 표, 그래프 등을 이용해 쉽게 표현하고 탐색이나 해석에 활용한다.
    - 정보 시각화 기술, 시각화 도구, 편집 기술, 실시간 자료 시각화 기술로 구성되어 있다.

## 2. 빅데이터 수집
### 1. 크롤링(Crawling)
- 무수히 많은 컴퓨터에 분산 저장되어 있는 문서를 수집하여 검색 대상의 색인으로 포함시키는 기술이다.
- 어느 부류의 기술을 얼마나 빨리 검색 대상에 포함시키는가로 우위를 결정한다.
- 크롤러(Crawler): 웹 에이전트를 이용하여 인터넷 링크를 따라다니며 방문한 사이트의 웹 페이지나 소셜 데이터 등 공개되어 있는 데이터를 수집
### 2. 로그 수집기
- 조직 내부에 있는 웹 서버나 시스템의 로그를 수집하는 소프트웨어이다.
- 웹 로그나 트랙잭션 및 클릭 로그 등 각종 로그를 하나의 데이터로 수집한다.
### 3. 센서 네트워크(Sensor Network)
- 유비쿼터스 컴퓨팅 구현을 위한 초경량 저전력의 많은 센서들로 구성된 유무선 네트워크이다.
- 센서를 통하여 획득된 여러 정보를 네트워크로 구성된 통합 환경 내에서 재구성하여 처리한다.
### 4. RSS Reader/Open API
- 데이터의 생산, 공유, 참여할 수 있는 환경인 웹 2.0을 구현하는 기술이다.
- 필요한 데이터를 프로그래밍을 통해 수집할 수 있다.
### 5. ETL 프로세스
- 데이터의 추출(Extract), 변환(Transform), 적재(Load)의 약어로, 다양한 원천 데이터를 취합해 추출하고 공통된 형식으로 변환하여 적재하는 과정이다.

## 3. 빅데이터 저장
### 1. NoSQL(Not-only SQL)
전통적인 관계형 데이터베이스와는 다르게 데이터 모델을 단순화하여 설계된 비관계형 데이터베이스로 SQL을 사용하지 않는 DBMS와 데이터 저장장치이다.
- 기존의 RDBMS 트랜잭션 속성인 원자성(Atomicity), 일관성(Consistency), 독립성(Isolation), 지속성(Durability)을 유연하게 적용한다.
- 데이터 업데이트가 즉각적으로 가능한 데이터 저장소이다.
- Cloudata, Hbase, Cassandra, MongoDB 등이 대표적이다.
### 2. 공유 데이터 시스템(Shared-data System)
- 일관성, 가용성(Availability), 분할 내성(Partition Tolerance) 중에서 최대 두 개의 속성만 보유할 수 있다. (CAP 이론)
- 분할 내성을 취하고 일관성과 가용성 중 하나를 포기하여 일관성과 가용성을 모두 취하는 기존 RDBMS보다 높은 성능과 확장성을 제공한다.

### 3. 병렬 데이터베이스 관리 시스템(Parallel Database Management System)
다수의 마이크로프로세서를 사용하여 여러 디스크에 질의, 갱신, 입출력 등 데이터베이스 처리를 동시에 수행하는 시스템이다.
- 확장성을 제공하기 위해 작은 단위의 동작으로 트랜잭션 적용이 필요하다.
- VoltDB, SAP HANA, Vertica, Greeplum, Netezza가 대표적이다.

### 4. 분산 파일 시스템
네트워크로 공유하는 여러 호스트의 파일에 접근할 수 있는 파일 시스템이다.
- 데이터를 분산하여 저장하면 데이터 추출 및 가공 시 빠르게 처리할 수 있다.
- GFS(Google File System), HDFS(Hadoop Distributed File System), 아마존 S3 파일 시스템이 대표적이다.

### 5. 네트워크 저장 시스템
이기종 데이터 저장 장치를 하나의 데이터 서버에 연결하여 총괄적으로 데이터를 저장 및 관리하는 시스템이다.
- SAN(Storage Area Network), NAS(Network Attached Storage)가 대표적이다.
    - NAS: 네트워크 결합 스토리지, 컴퓨터를 직접 연결하지 않고 근거리 통신 네트워크를 동해 데이터를 주고 받는 방식

## 4. 빅데이터 처리
### 1. 분산 시스템과 병렬 시스템
- 분산 시스템
    - 네트워크상에 분산되어 있는 컴퓨터를 단일 시스템인 것처럼 구동하는 기술이다.
    - 분산 시스템에 속한 각 노드는 독립된 시스템이다.
    - 독립 컴퓨터의 집합으로 만들었으나 마치 단일 시스템인 것 처럼 수행되어야 한다.
- 병렬 시스템
    - 문제 해결을 위해 CPU 등의 자원을 데이터 버스나 지역 통신 시스템 등으로 연결하여 구동하는 기술이다.
    - 분할된 작업을 동시에 처리하여 계산 속도를 빠르게 한다.

- 용어는 구분되어 사용되기도 하지만 서로 중첩되는 부분이 많아 실제 시스템에서도 이 둘을 명확히 구분하기는 어렵다.
- 두 개념을 아우르는 분산 병렬 컴퓨팅이라는 용어를 사용한다.
- 병렬(Parallel) 데이터베이스의 특징
    - 분산 아키텍처
    - 병렬 처리/고성능 처리
    - 데이터 파티셔닝을 통한 데이터 병렬성
    - 데이터 복제와 분산

### 2. 분산 병렬 컴퓨팅
- 다수의 독립된 컴퓨팅 자원을 네트워크상에 연결하여 이를 제어하는 미들웨어(Middleware)를 이용해 하나의 시스템으로 동작하게 하는 기술이다.
#### 분산 병렬 컴퓨팅 시 고려사항
- 전체 작업의 배분 문제
    - 전체 작업을 잘 쪼개어 여러 개의 작은 작업으로 나눠야 한다.
- 각 프로세서에서 계산된 중간 결과물을 프로세서 간 주고받는 문제
    - 효율적인 통신은 성능과 직결된다.
    - 보통 단일 시스템은 전체 작업을 노드의 수만큼 균등하게 나눈다.
    - 이종 시스템은 컴퓨팅 능력에 따라 전체 작업을 배분한다.
    - 노드 간의 통신을 최소화하는 기법 등이 반영되면 자원을 좀 더 효율적으로 사용할 수 있어 성능 향상에 도움이 된다.
- 서로 다른 프로세서 간 동기화 문제
    - 데이터 병렬 처리에서 동기적 방법을 사용할 경우 프로세서는 특정 계산이 끝나거나 특정 데이터를 넘겨받을 때까지 반드시 대기하여야 한다.
    - 동기적 방법의 경우 송신자는 수신자에게서 데이터를 받았다는 응답이 올 때까지 대기하여야 한다.
    - 비동기적 방법에서는 결과 메세지를 보낸 즉시 다음 작업을 계속할 수 있다.
    - 비동기적 방법의 경우 프로세서는 기다릴 필요가 없지만, 계산 과정이 적합한지는 확인해야 한다.

### 3. 하둡(Hadoop)
분산 처리 환경에서 대용량 데이터 처리 및 분석을 지원하는 오픈 소스 소프트웨어 프레임워크이다.
- 야후에서 최초로 개발했으며, 지금은 아파치 소프트웨어 재단에서 프로젝트로 관리되고 있다.
- 하둡 분산파일시스템인 HDFS(Hadoop Distributed File System)와 분산칼럼기반 데이터베이스인 Hbase, 분산 컴퓨팅 지원 프레임워크인 맵리듀스(MaoReduce)로 구성되어 있다.
- 분산파일시스템을 통해 수 천대의 장비에 대용량 파일을 나누어 저장할 수 있는 기능을 제공한다.
    - 분산파일시스템에 저장된 대용량의 데이터들을 맵리듀스를 이용하여 실시간으로 처리 및 분석 가능하다.
- 하둡의 부족한 기능을 보완하는 하둡 에코시스템이 등장하여 다양한 솔루션을 제공한다.

### 4. 아파치 스파크(Apache Spark)
실시간 분산형 컴퓨팅 플랫폼으로 In-Memory 방식으로 처리를 하며 하둡보다 처리속도가 빠르다.
- 스칼라 언어로 개발되었지만 스칼라뿐만 아니라 Java, R, Python을 지원한다.

### 5. 맵리듀스(MapReduce)
구글에서 개발한 방대한 양의 데이터를 신속하게 처리하는 프로그래밍 모델로 효과적인 병렬 및 분산 처리를 지원한다.
- 런타임(Runtime)에서의 입력 데이터 분할, 작업 스케줄링, 노드 고장, 노드간의 데이터 전송 작업이 맵리듀스 처리 성능에 많은 영향을 미친다.
- 맵리듀스 처리단계
    - 1단계: 입력 데이터를 읽고 분할한다.
    - 2단계: 분할된 데이터를 할당해 맵 작업을 수행한 후, 그 결과인 중간 데이터를 통합 및 재분할한다.
    - 3단계: 통합 및 재분할된 중간 데이터를 셔플(Shuffle)한다.
    - 4단계: 셔플된 중간 데이터를 이용해 리듀스 작업을 수행한다.
    - 5단계: 출력 데이터를 생성하고, 맵리듀스 처리를 종료한다.
- 맵리듀스 처리
[ABR], [CCR], [ACB] 데이터를 입력받아 각 원소의 개수를 구하고자 한다.
    - 입력받은 데이터를 3개로 균등하게 분할한다.
    - 분할된 3개의 데이터를 할당하여 맵 작업을 수행한 후, 그 중간 결과값을 [A], [B], [C], [R]처럼 같은 값끼리 통합 및 재분할한다.
    - 통합 및 재분할된 중간 결과값을 셔플한다.
    - 셔플된 중간 결과값을 이용해 리듀스 작업을 수행하여 [A], [B], [C], [R] 각각의 개수를 구한다.

## 5. 빅데이터 분석
### 1. 데이터 분석 방법의 분류
- 탐구 요인 분석(EFA: Exploratory Factor Analysis): 데이터 간 상호 관계를 파악하여 데이터를 분석하는 방법이다.
- 확인 요인 분석(CFA: Confirmatory Factor Analysis): 관찰된 변수들의 집합 요소 구조를 파악하기 위한 통계적 기법을 통해 데이터를 분석하는 방법이다.

### 2. 데이터 분석 방법
- 분류(Classification)
    - 미리 알려진 클래스들로 구분되는 학습 데이터셋(Data Set)을 학습시켜 새로 추가되는 데이터가 속할 만한 데이터 셋을 찾는 지도학습 방법이다.
- 군집화(Clustering)
    - 특성이 비슷한 데이터를 하나의 그룹으로 분류하는 방법으로, 분류와 달리 학습 데이터셋을 이용하지 않는 비지도학습 방법이다.
- 기계학습(Machine Learning)
    - 인공지능 분야에서 인간의 학습을 모델링한 방법이다.
    - 의사결정트리 등 기호적 학습과 신경망이나 유전 알고리즘 등 비기호적 학습, 베이지안이나 은닉 마코프 등 확률적 학습 등 다양한 기법이 있다.
- 텍스트 마이닝(Text Mining)
    - 자연어 처리 기술을 이용해 인간의 언어로 쓰인 비정형 텍스트에서 유용한 정보를 추출하거나 다른 데이터와의 연관성을 파악하기 위한 방법이다.
    - 분류나 군집화 등 빅데이터에 숨겨진 의미 있는 정보를 발견하는데 사용하기도 한다.
- 웹 마이닝(Web Mining)
    - 인터넷을 통해 수집한 정보를 데이터 마이닝 방법으로 분석하는 응용분야이다.
- 오피니언 마이닝(Opinion Mining)
    - 온라인의 다양한 뉴스와 소셜 미디어 코멘트 또는 사용자가 만든 콘텐츠에서 표현된 의견을 추출, 분류, 이해하는 응용분야이다.
- 리얼리티 마이닝(Reality Mining)
    - 휴대폰 등 기기를 사용하여 인간관계와 행동 양태 등을 추론하는 응용분야이다.
    - 통화량, 통화 위치, 통화 상태, 통화 대상, 통화 내용 등을 분석하여 사용자의 인간관계나 행동 특성을 찾아낸다.
- 소셜 네트워크 분석(Social Network Analysis)
    - 수학의 그래프 이론을 바탕으로 소셜 네트워크 서비스에서 네트워크 연결 구조와 강도를 분석하여 사용자의 명성 및 영향력을 측정하는 방법이다.
- 감정 분석(Sentiment Analysis)
    - 문장의 의미를 파악하여 글의 내용에 긍정 또는 부정, 좋음 또는 나쁨을 분류하거나 만족 또는 불만족 강도를 지수화하는 방법이다.
    - 도출된 지수를 이용하여 고객의 감성 트렌드를 시계열로 분석하고, 고객의 감성 변화에 기업들이 신속하게 대응 및 부정적인 의견의 확산을 방지하는데 활용할 수 있다.

# 3. 빅데이터와 인공지능
## 1. 인공지능(AI: Artificial Intelligence)
### 1. 인공지능의 정의
- 인공지능은 기계를 지능화하는 노력이며, 지능화란 객체가 환경에서 적절히, 그리고 예지력을 갖고 작동하도록 하는 것이다.(Artificial Intelligence and life in 2030, 스탠퍼드 대학교 AI100)
- 인공지능은 합리적 행동 수행자(Rational Agent)이며, 어떤 행동이 최적의 결과를 낳을 수 있도록 하는 의사결정 능력을 갖춘 에이전트를 구축하는 것이다. (Artificial Intelligence - a modern approach [3rd edition], 러셀과 노빅)
- 인공지능은 설정한 목표를 극대화하는 행동을 제시하는 의사결정 로직이다.
- 인공지능은 사람과 흡사한 생각과 행동에 초점을 맞춘 정의도 소개된 바 있으나, 인공지능 구현방법이 구체화 될수록 인간처럼 보다는 합리성을 더 강조하고 있다.

### 2. 인공지능과 기계학습 및 딥러닝의 관계
- 인공지능을 논할 때 기계학습과 딥러닝을 혼재하여 사용한다.
    - 인공지능은 사람이 생각하고 판단하는 사고 구조를 구축하려는 전반적인 노력이다.
    - 기계학습은 인공지능의 연구 분야 중 하나로 인간의 학습 능력과 같은 기능을 축적된 데이터를 활용하여 실현하고자 하는 기술 및 방법이다.
    - 딥러닝은 기계학습 방법 중 하나로 컴퓨터가 많은 데이터를 이용해 사람처럼 스스로 학습할 수 있도록 인공신경망 등의 기술을 이용한 기법이다.

### 3. 딥러닝(Deep Learning)의 특징
- 딥러닝은 제프리 힌튼(Geoffrey Everest Hinton)의 노력으로 함수추정 방법으로써의 신경망 관점에서 정보를 압축, 가공, 재현하는 알고리즘으로 일반화하면서 인공지능의 핵심 동인이 되었다.
- 깊은 구조에 의해 엄청난 양의 데이터를 학습할 수 있는 특징을 갖고 있어 인공지능 발전에 크게 기여하였다.
    - 딥러닝의 학습을 위한 데이터의 확보는 곧 우수한 인공지능 개발과 깊은 관련성이 있다.

### 4. 기계학습의 종류
- 지도학습(Supervised Learning)
    - 학습 데이터로부터 하나의 함수를 유추해내기 위한 방법이다.
        - 학습 데이터는 일반적으로 입력 객체에 대한 속성을 벡터 형태로 포함하고 있으며 각각의 벡터에 대해 원하는 결과가 무엇인지 표시되어 있다.
        - 유추된 함수 중 연속적인 값을 출력하는 것을 회귀분석이라 한다.
        - 주어진 입력 벡터가 어떤 종류의 값인지 표시하는 것을 분류라 한다.
    - 지도 학습기(Supervised Learner)가 하는 작업은 훈련 데이터로 부터 주어진 데이터에 대해 예측하고자 하는 값을 올바로 추측해내는 것이다.
        - 학습기는 알맞은 방법을 통하여 기존의 훈련 데이터로부터 나타나지 않던 상황까지도 일반화하여 처리할 수 있어야 한다.
- 비지도학습(Unsupervised Learning)
    - 데이터가 어떻게 구성되었는지를 알아내는 문제의 범주에 속한다.
    - 지도학습 혹은 강화학습과는 달리 입력값에 대한 목표치가 주어지지 않는다.
    - 통계의 밀도 추정(Density Estimation)과 깊은 연관이 있으며, 데이터의 주요 특징을 요약하고 설명할 수 있다.
    - 군집화, 독립성분분석(Independent Component Analysis) 방법 등이 있다.
- 준지도학습(Semi-supervised Learning)
    - 목표값이 표시된 데이터와 표시되지 않은 데이터를 모두 학습에 사용하는 것을 말한다.
        - 대개의 경우 이러한 방법에 사용되는 학습 데이터는 목표값이 표시된 데이터 보다 표시되지 않은 데이터를 많이 갖고 있다.
        - 목표값이 충분히 표시된 학습 데이터를 사용하는 지도학습과 목표값이 표시되지 않은 학습 데이터를 사용하는 비지도학습 사이에 위치한다.
    - 많은 기계학습 연구자들이 목표값이 없는 데이터에 적은 양의 목표값을 포함한 데이터를 사용할 경우 학습 정확도에 있어서 상당히 좋아짐을 확인하였다.
    - 두 개 이상의 학습기 각각이 예제를 통해 훈련되는 상호 훈련 방법 등이 있다.
- 강화학습(Reinforcement Learning)
    - 행동심리학에서 영감을 받았으며, 선택 가능한 행동들 중 보상을 최대화하는 행동 혹은 순서를 선택하는 방법이다.
        - 운용과학, 제어이론에서 강화학습은 '근사 동적 계획법'이라 부르는 분야에서 연구된다.
        - 경제학, 게임이론 분야에서 강화학습은 어떻게 제한된 합리성하에서 평형이 일어날 수 있는지를 설명하는 데에 사용되기도 한다.
    - 강화학습의 초점은 학습 과정(on-line)에서의 성능이며, 이는 탐색(exploration)과 이용(exploitation)의 균형을 맞춤으로써 제고된다.
    - 탐색과 이용의 균형 문제는 강화학습에서 가장 많이 연구된 문제로, 다중슬롯머신 문제(multi-armed bandit problem)와 유한한 마르코프 결정 과정 등에서 연구되었다.

### 5. 기계학습 방법에 따른 인공지능 응용분야
#### 지도학습
- 분류모형
    - 이미지 인식
    - 음성 인식
    - 신용평가 및 사기검출
    - 불량예측 및 원인발굴
- 회귀모형
    - 시세/가격/주가 예측
    - 강우량 예측 등
#### 비지도 학습
    - 군집분석
        - 텍스트 토픽 분석
        - 고객 세그멘테이션
    - 오토인코더(AutoEncoder)
        - 이상징후 탐지
        - 노이즈 제거
        - 텍스트 벡터화
    - 생성적 적대 신경망(Generative Adversarial Network)
        - 시뮬레이션 데이터 생성
        - 누락 데이터 생성
        - 패션 데이터 생성 등
#### 강화학습
- 강화학습
    - 게임 플레이어 생성
    - 로봇 학습 알고리즘
    - 공급망 최적화 등

## 2. 인공지능 데이터 학습의 진화
### 1. 전이학습(Transfer Learning)
전이학습은 기존의 학습된 모델의 지식을 새로운 문제에 적용하여 학습을 빠르고 효율적으로 수행하는 머신러닝 기법이다. 전이학습은 기존의 모델이 학습한 특성, 가중치, 표현 등을 새로운 모델에 전달하여 새로운 작업에 적용하는 방식으로 작동한다. 비슷한 분야에서 학습된 딥러닝 모형을 다른 문제를 해결하기 위해 사용하고자 할 때 적은 양의 데이터로도 좋은 결과를 얻을 수 있다.
- 주로 이미지, 언어, 텍스트 인식과 같이 지도학습 중 분류모형인 인식(recognition) 문제에 활용 가능하다.
    - 인식 문제의 경우 데이터 표준화가 가능하여 사전학습모형 입력형식에 맞출 수 있다.

### 2. 전이학습 기반 사전학습모형(Pre-trained Model)
학습 데이터에 의한 인지능력을 갖춘 딥러닝 모형에 추가적인 데이터를 학습시키는 방식이다.
- 데이터 학습량에 따라 점차 발전하는 것도 중요하지만, 응용력을 갖추는 것 또한 필수적이다.
- 상대적으로 적은 양의 데이터로도 제한된 문제에 인공지능 적용이 가능하다.
    - 이미 학습된 사전학습모형도 데이터를 함축한 초보적 인공지능으로서 충분한 가치를 지닌 새로운 의미의 데이터라고 할 수 있다.

### 3. BERT(Bidirectional Encoder Representations from Transformers)
2018년 구글에서 발표한 언어인식 사전학습모형이다. 확보된 언어 데이터의 추가 학습을 통한 신속한 학습이 가능하다.
- 다층의 임베딩 구조를 통해 1억2천 개가 넘는 파라미터로 구성된 획기적인 모형이다.
- 256개까지의 문자가 입력되어 768차원 숫자 벡터가 생성되는 방식이다.
- 언어 인식뿐 아니라 번역, 챗봇의 Q&A 엔진으로 활용 가능하다.

## 3. 빅데이터와 인공지능의 관계
### 1. 인공지능을 위한 학습 데이터 확보
- 학습 데이터 측면을 고려한 양질의 데이터 확보는 결국 성공적인 인공지능 구현과 직결된다.
- 딥러닝은 깊은 구조를 통해 무한한 모수 추정이 필요한 만큼 많은 양의 데이터가 필요하다.
- 인공지능 학습에 활용될 수 있는 데이터로 가공이 필요하며, 학습의 가이드를 제공해주는 애노테이션 작업이 필수적이다.
    - Annotation: 데이터상의 주석 작업으로 딥러닝과 같은 학습 알고리즘이 무엇을 학습하여야 하는지 알려주는 표식 작업

### 2. 학습 데이터의 애노테이션 작업
많은 데이터 확보 후 애노테이션을 통해 학습이 가능한 데이터로 가공하는 작업이 필요하다.
- 작업의 특성 상 많은 수작업이 동반되며, 이로 인해 인공지능 사업은 노동직얍적이라는 인식을 만들어냈다.

### 3. 애노테이션 작업을 위한 도구로써의 인공지능
인공지능 시장이 확장되며 애노테이션 작업을 전문으로 하는 기업의 수가 증가하였다.
- 경쟁으로 인해 학습용 데이터에 대한 보안 및 애노테이션 결과에 대한 품질 요구수준이 높아졌다.
- 기업들은 데이터 업로드 및 애노테이션 도구, 작업 모니터링을 위한 플랫폼을 제공하기 시작했다.
- 현재 자동으로 애노테이션을 수행해 주는 인공지능 기반의 애노테이션 도구를 제공하는 서비스로 진화 중이다.

## 4. 인공지능의 기술동향
### 1. 기계학습 프레임워크 보급 확대
- 구글브레인이 개발한 Tensorflow는 파이썬 기반 딥러닝 라이브러리로 여러 CPU 및 GPU와 플랫폼에서 사용 가능하다.
- Keras는 딥러닝 신경망 구축을 위한 단순화된 인터페이스를 가진 라이브러리이며, 몇 줄의 코드만으로 딥러닝 모형 개발이 가능하다.

### 2. 생성적 적대 신경망(GAN: Generative Adversarial Networks)
GAN은 두 개의 인공신경망으로 구성된 딥러닝 이미지 생성 알고리즘이다.
- 생성자가 가짜 사례를 생성하면 감별자가 진위를 판별하도록 구성한 후 이들이 적대적 관계 속에서 공방전을 반복하도록 한다.
    - 가짜 사례의 정밀도를 점점 더 진짜 사례와 구별하기 어려운 수준으로 높이는 방식으로 작동한다.
- 주로 새로운 합성 이미지를 생성하는 분석에 많이 적용되어 왔으나, 점차 다른 분야에 응용하는 사례가 늘고 있다.

### 3. 오토인코더(Auto-encoder)
오토인코더는 라벨이 설정되어 있지 않은 학습 데이터로부터 더욱 효율적인 코드로 표현하도록 학습하는 신경망이다.
- 입력 데이터의 차원을 줄여 모형을 단순화시키기 위해 활용할 수 있다.

### 4. 설명 가능한 인공지능(XAI: eXplinable AI)
설명 가능한 인공지능은 결론 도출 과정에 대한 근거를 차트나 수치 또는 자연어 형태의 설명으로 제공한다.
- 기존의 기계학습은 정확한 예측을 할 수 있도록 하는 방향으로 개발되어 왔다.
    - 기존 기계학습의 완성된 모형은 내부 구조가 매우 복잡하고 의미를 이해하기 어려워 일종의 블랙박스 모형이라 불리었다.

### 5. 기계학습 자동화(AutoML)
기계학습 자동화는 명칭 그대로 기계학습의 전체 과정을 자동화하는 것이다.
- 세부적으로는 데이터 전처리, 변수 생성, 변수 선택, 알고리즘 선택, 하이퍼파라미터 최적화 등의 기능을 수행한다.
- 기계학습 모형 개발 과정의 생산성을 높이며 비전문가들의 활용을 용이하게 할 것으로 기대된다.

### 6. 거대 언어 모델(LLM: Large Language Model)
- 거대 언어 모델은 대형 언어 모델이라고도 불리며 수십억 개 이상의 파라미터로 구성된 신경망을 기반으로 학습된 언어 모델이다.
- LLM의 작동방식은 크게 토큰화, 트랜스포머 모델, 프롬프트의 3가지로 구분된다.
- 토큰화는 자연어 처리의 일부로 일반 인간 언어를 저수준 기계 시스템(LLMS)이 이해할 수 있는 시퀀스로 변환하는 작업을 말한다.
- 트랜스포머 모델은 문장 속 단어와 같은 순차 데이터 내의 관계를 추적해 맥락과 의미를 학습하는 신경망으로 텍스트와 음성을 거의 실시간으로 생성한다.
- 프롬프트는 거대 언어 모델에 제공하는 정보로 더 정확한 프롬프트를 제공할수록 다음 단어를 더 잘 예측하고 정확한 문장을 구성할 수 있다.

## 5. 인공지능의 한계점과 발전방향
### 1. 국내시장의 한계
- 국내에서 축적한 머신러닝 및 인공지능과 관련한 수학, 통계학적 이해도는 낮은 수준이다.
- 인공지능 개발을 위한 데이터 확보 및 그 중요성에 대한 인식이 부족하다.

### 2. 인공지능의 미래
- 딥러닝의 재학습 및 전이학습 특성을 활용한 사전학습모형이 새로운 데이터 경제의 모습이 될 것이다.
    - 데이터 경제는 수집, 학습용 데이터로의 가공, 전이학습용 사전학습 모형으로 구분되고 있다.
- 마스킹이나 라벨링 등의 애노테이션 작업을 통해 학습용 데이터를 가공하는 산업이 확산되고 있다.
- 복잡한 BERT의 학습을 위한 구글의 클라우드 서비스와 같은 확장된 개념의 데이터 경제로 파생될 것으로 보인다.

# 4. 개인정보 개요
## 1. 개인정보의 정의와 판단기준
### 1. 개인정보의 정의
- 살아있는 개인에 관한 정보로서 개인을 알아볼 수 있는 정보이다.
- 해당 정보만으로 특정 개인을 알아볼 수 없더라도 다른 정보와 쉽게 결합하여 알아볼 수 있는 정보를 포함한다.

### 2. 개인정보의 판단기준
- '생존하는' '개인에 관한' 정보여야 한다.
- '정보'의 내용, 형태 등은 제한이 없다.
- 개인을 '알아볼 수 있는' 정보여야 한다.
    - 다른 정보와 '쉽게 결합하여' 개인을 알아볼 수 있는 정보도 포함된다.

## 2. 개인정보의 이전
개인정보가 다른 사람(제3자)에게 이전되거나 공동으로 처리하게 하는 것이다. 개인 정보의 처리 위탁과 제3자 제공으로 분류된다.
### 1. 개인정보의 처리 위탁
- 개인정보처리자의 업무를 처리할 목적으로 제3자에게 이전되는 것이다.
- 개인정보를 '제공하는 자'의 업무처리와 이익을 위하는 경우이다.
### 2. 개인정보의 제3자 제공
- 해당 정보를 제공받는 자의 고유한 업무를 처리할 목적 및 이익을 위하여 개인정보가 이전되는 것이다.
- 개인정보를 '제공받는 자'의 업무처리와 이익을 위하는 경우이다.

## 3. 개인정보의 보호
### 1. 개인정보의 보호조치
- 조직 내부의 정보보안 방침과 개인정보보호법에 위배되지 않도록 개인정보보호 가이드라인을 점검한다.
- 데이터를 외부에 공개하는 경우 가이드라인에서 정한 규칙을 준수하는지 반드시 확인한다.
- 가이드라인에 명시되지 않은 경우 관계기관이나 조직 내부의 법무가이드를 받은 후 적절한 범위 안에서 데이터를 활용하도록 한다.
- 개인 정보 보호를 위해 주기적인 패스워드 변경, 시스템 패스워드 관리 보안 강화, 의심스러운 메일 열람 금지, 정기적인 보안교육 참여 등을 유도한다.
- 백신의 설치 및 최신버전으로 유지하고, 개인정보를 과하게 요구하는 사이트의 가입을 자제한다.
### 2. 빅데이터 개인정보보호 가이드라인(방송통신위원회)
- 비식별화: 수집 시부터 개인식별 정보에 대한 철저한 비식별화 조치
    - 개인정보가 포함된 공개된 정보 및 이용내역정보는 비식별화 조치를 취한 후 수집, 저장, 조합, 분석 및 제3자 제공 등이 가능하다.
- 투명성 확보: 빅데이터 처리 사실, 목적 등의 공개를 통한 후 투명성 확보
    - 개인정보 취급방침을 통해 비식별화 조치 후 빅데이터 처리 사실, 목적, 수집 출처 및 정보 활용 거부권 행사 방법 등을 이용자에게 투명하게 공개한다.
- 재식별 시 조치: 개인정보 재식별 시, 즉시 파기 및 비식별화 조치
    - 빅데이터 처리 과정 및 생성정보에 개인정보가 재식별될 경우, 즉시 파기하거나 추가적인 비식별화 조치하도록 한다.
- 민감정보 및 비밀정보 처리: 민감정보 및 통신비밀의 수집, 이용, 분석 등 처리 금지
    - 특정 개인의 사상, 신념, 정치적 견해 등 민감정보의 생성을 목적으로 정보의 수집, 이용, 저장, 조합, 분석 등 처리 금지한다.
    - 이메일, 문자 메시지 등 통신 내용의 수집, 이용, 저장, 조합, 분석 등 처리 금지한다.
- 기술적, 관리적 보호조치: 수집된 정보의 저장, 관리 시 '기술적, 관리적 보호조치' 시행
    - 비식별화 조치가 취해진 정보를 저장, 관리하고 있는 정보 처리시스템에 대한 기술적, 관리적 보호조치 적용한다.
        - (보호조치) 침입차단시스템 등 접근 통제장치 설치, 접속 기록에 대한 위,변조 방지 조치, 백신 소프트웨어 설치, 운영 등 악성 프로그램에 의한 침해 방지 조치한다.

### 3. 개인정보 보호를 위한 고려사항
- 기업은 적법하게 정보주체의 권리를 보호하면서 데이터의 효율적인 이용 방안을 모색하는 것이 중요하다.
- 데이터와 관련된 주요 법령 및 규제기관의 가이드라인을 지속적으로 파악하고 내부 프로세스를 사전에 검토하여야 한다.
- 적용되는 법령에 따른 내부 개인정보 컴플라이언스 체계를 구축하여야 한다.
- 데이터를 이전할 경우에는 관련 법률에 따른 적법한 프로세스를 마련하여야 한다.

### 4. 개인정보보호 관련 법률
- 비즈니스 모델과 처리하는 데이터에 따라 '개인정보보호법'과 '정보통신망 이용촉진 및 정보보호 등에 관한 법률' 그리고 '신용정보의 이용 및 보호에 관한 법률'등을 기본적으로 검토하여야 한다. (데이터 3법)
- 이 외 경우에 따라 '위치정보의 보호 및 아용 등에 관한 법률'과 '정보통신기반 보호법' 및 '국가정보화 기본법'과 '전자정부법'등을 추가적으로 검토하여야 한다.

# 5. 개인정보 법ㆍ제도
## 1. 개인정보보호법
### 1. 개인정보보호법의 개요
- 당사자의 동의 없는 개인정보 수집 및 활용하거나 제3자에게 제공하는 것을 금지하는 등 개인정보보호를 강화환 내용을 담아 제정한 법률이다.
- 상대방의 동의 없이 개인정보를 제3자에게 제공하면 5년 이하의 징역이나 5,000만 원 이하의 벌금에 처할 수 있다.
- 개인정보 보호를 위한 법체계를 일원화하고 개인의 권익 보호를 강화하기 위한 법으로 2011년 3월 29일 제정되어 같은 해 9월 30일부터 시행되었다.

### 2. 개인정보의 범위(제2조 제1호)
- '개인정보'란 살아 있는 개인에 관한 정보로서 성명, 주민등록번호 및 영상 등을 통하여 개인을 알아볼 수 있는 정보(해당 정보만으로는 특정 개인을 알아볼 수 없더라도 다른 정보와 쉽게 결합하여 알아볼 수 있는 것을 포함)를 말한다.
- 어떤 정보가 개인정보에 해당하는지는 그 정보가 특정 개인을 알아볼 수 있게 하는 다른 정보와 쉽게 결합할 수 있는가에 따라 결정된다.
- 법원은 그 정보 자체로는 누구의 정보인지를 알 수 없더라도 다른 정보와 결합 가능성을 비교적 넓게 인정하여 개인정보에 해당한다 판단하고 있다.
- 광범위한 데이터가 개인정보에 해당하여 이 법이 적용될 수 있다는 점을 유의해야 한다.

### 3. 개인정보의 처리 위탁
- 일정한 내용을 기재한 문서에 의하여 업무 위탁이 이루어져야 한다.(개인정보보호법 제26조 제1항)
- 위탁하는 업무의 내용과 수탁자를 정보주체에게 알려야 하는바, 개인정보처리방침에 해당 내용을 추가하여 공개하거나, 사업장 등의 보기 쉬운 장소에 게시하는 방법 등을 시행해야 한다.(개인정보보호법 제26조 제 3항, 동법 시행령 제28조 제3항)
- 수탁자에 대한 교육 및 감독 의무를 부담하게 된다.(개인정보보호법 제 26조 제4항)
- 수탁자가 위탁 받은 업무와 관련하여 개인정보를 처리하는 과정에서 개인정보보호법을 위반하여 발생한 손해배상책임에 대하여는 수탁자를 개인정보처리자의 소속 지원으로 본다.(개인정보보호법 제26조 제6항)
- 손해가 발생한 경우 정보주체의 손해배상 청구에 대해 위탁자가 책임을 질 수 있다.

### 4. 개인정보의 제3자 제공
- 정보주체로부터 개인정보 제3자 제공 동의를 받아야 한다.(개인정보보호법 제17조 제1항)

### 5. 개인정보 처리 위탁과 제3자 제공 판단 기준
서울중앙지방법원 2018. 8. 16. 선고 2017노1296 판결 참조
- 개인정보의 취득목적과 방법
- 대가 수수 여부
- 수탁자에 대한 실질적인 관리ㆍ감독 여부
- 정보주체 또는 이용자의 개인정보 보호 필요성에 미치는 영향
- 개인정보를 이용할 필요가 있는 자가 실질적으로 누구인지 등

### 6. 비식별 개인정보의 이전
- 정보주체 또는 제3자의 이익을 부당하게 침해할 우려가 있는 경우는 제외한다.
- 통계작성 및 학술연구 등의 목적을 위하여 필요한 경우로서 '특정 개인을 알아볼 수 없는 형태로 개인정보'를 제공할 수 있도록 규정하고 있다.(개인정보보호법 제18조 제2항 제4호)
- 데이터 제공이 목적에 부합하는지, 특정 개인을 알아볼 수 없는 형태로 제공하는지에 대해 사전에 검토하여야 한다.

## 2. 정보통신망 이용촉진 및 정보보호 등에 관한 법률(정보통신망법)
### 1. 정보통신망법의 개요
- 정보통신망의 개발과 보급 등 이용 촉진과 함께 통신망을 통해 활용되고 있는 정보보헹 관해 규정한 법률이다.
- 이용자의 동의를 받지 않고 개인정보를 수집하거나 제3자에게 개인정보를 제공한 경우, 법정대리인의 동의 없이 만14세 미만의 아동의 개인정보를 수집한 경우, 악성프로그램을 전달 또는 유포한 경우 등은 5년 이하의 징역 또는 5,000만 원 이하의 벌금에 처해진다.
### 2. 개인정보의 처리 위탁
- 원칙적으로는 개인정보 처리위탁을 받는 자, 개인정보 처리위탁을 하는 업무의 내용을 이용자에게 알리고 동의를 받아야 한다.
- 단, 정보통신서비스 제공자 등은 정보통신서비스의 제공에 관한 계약을 이행하고 이용자의 편의 증진 등을 위하여 필요한 경우에는 고지절차와 동의절차를 거치지 않고, 이용자에게 이를 알리거나 개인정보 처리방침 등에 이를 공개할 수 있다.(정보통신망법 제25조 제2항)
- 만일 제3자에게 데이터 분석을 위탁할 경우, 해당 서비스가 정보통신 서비스 제공에 관한 계약을 이행하고 이용자의 편의 증진을 위한 것인지 검토해야 한다.

## 3. 신용정보의 이용 및 보호에 관한 법률(신용정보보호법)
### 1. 신용정보보호법의 개요
- 개인신용정보를 신용정보 회사 등에게 제공하고자 하는 경우에 해당 개인으로부터 서면 또는 공인전자서명이 있는 전자문서에 의한 동의 등을 얻어야 한다.
- 신용정보주체는 신용정보호회사 등이 본인에 관한 신용정보를 제공하는때에는 제공받은 자, 그 이용 목적, 제공한 본인정보의 주요 내용 등을 통보하도록 요구하거나 인터넷을 통하여 조회할 수 있도록 요구할 수 있다.
- 신용정보회사 등이 보유하고 있는 본인정보의 제공 또는 열람을 청구할 수 있고, 사실과 다른 경우에는 정정을 청구할 수 있다.

### 2. 신용정보의 범위(제2조 제1호 및 제2호, 제34조 제1항)
- "신용정보"란 금융거래 등 상거래에 있어서 거래 상대방의 신용을 판단할 때 필요한 정보로서 다음 각 목의 정보를 말한다.
    - 특정 신용정보주체를 식별할 수 있는 정보
    - 신용정보주체의 거래내용을 판단할 수 있는 정보
    - 신용정보주체의 신용도를 판단할 수 있는 정보
    - 신용정보주체의 신용거래능력을 판단할 수 있는 정보
    - 그 밖에 유사한 정보

### 3. 개인신용정보
- "개인신용정보"란 신용정보 중 개인의 신용도와 신용거래능력 등을 판단할 때 필요한 정보를 말한다.
- "개인신용정보"는 기업 및 법인에 관한 정보를 제외한 살아 있는 개인에 관한 정보로서 성명, 주민등록번호 등을 통하여 개인을 알아볼 수 있는 정보이며, 신용정보주체의 거래내용, 신용도, 신용거래능력 등과 결합되는 경우에만 개인신용정보에 해당한다.

### 4. 개인신용정보의 처리 위탁
- 신용정보회사 등은 그 업무 범위에서 의뢰인의 동의를 받아 다른 신용정보회사에 신용정보의 수집ㆍ조사를 위탁할 수 있다.
- 개인신용정보 처리에 대한 업무 위탁의 경우에는 수집된 신용정보의 처리를 자본금 또는 자본총액이 1억 원 이상인 기업으로서 신용정보관리ㆍ보호인 등을 지정한 자에게 위탁할 수 있다.
- 신용정보회사, 신용정보집중기관, 은행, 금융지주회사, 금융투자업자, 보험회사 등은 신용정보 처리 위탁 시 금융위원회에 보고해야 하며, 이에 관한 구체적 사항은 '금융회사의 정보처리 업무 위탁에 관한 규정'에 따른다.
- 특정 신용정보주체를 식별할 수 있는 정보는 암호화하거나 봉함 등의 보호조치를 하여야 하며, 신용정보가 분실, 도난, 유출, 변조 또는 훼손당하지 않도록 수탁자를 연 1회 이상 교육하여야 한다.
- 위탁계약의 이행에 필요한 경우로서 수집된 신용정보의 처리를 위탁하기 위하여 제공하는 경우 정보주체의 동의를 받지 않아도 된다(신용정보보호법 제17조, 동법 시행령 제14조)

### 5. 개인신용정보의 제3자 제공
- 개인신용정보를 타인에게 제공하려는 경우 정보주체에 서비스 제공을 위하여 필수적 동의 사항과 그 밖의 선택적 동의 사항을 구분하여 설명한 후 각각 동의를 받도록 하고 있다.(신용정보보호법 제32조, 제34조 등)
- 기타 개인정보 제공 시 개인정보보호법이 적용된다.

### 6. 개인식별정보
- "개인식별정보"란 생존하는 개인의 성명, 주소 및 주민등록번호, 여권번호, 운전면허번호, 외국인등록번호, 국내거소신고번호 및 성별, 국적 등 개인을 식별할 수 있는 정보를 말한다.

### 특별법
- 일반법에서 적용 범위를 한정 혹은 내용을 특별히 정해 놓은 법이다.
- 일반법과 특별법이 저촉되면 특별법이 먼저 적용되고, 특별법에 규정이 없는 사항에 대해서는 일반법이 적용된다.
- 정보통신서비스 제공자에 대하여는 정보통신망법(특별법)이 우선 적용되지만, 정보통신망법에 특별한 규정이 없고 개인정보보호법과 상호 모순ㆍ충돌하지 않는 경우에는 개인정보보호법(일반법)이 적용된다.
- 신용정보보호법 제3조의2는 "개인정보의 보호에 관하여 이 법에 특별한 규정이 있는 경우를 제외하고는 '개인정보보호법'에서 정하는 바에 따른다."라고 하고 있으므로 신용정보보호법은 개인정보보호법에 대해 특별법의 지위를 가진다.
- 법률이 상호 모순, 저촉되는 경우에는 신법이 구법에, 그리고 특별법이 일반법에 우선하나, 법률이 상호 모순되는지 여부는 각 법률의 입법목적, 규정사항 및 그 적용범위 등을 종합적으로 검토하여 판단하여야 한다.

## 4. 2020년 데이터 3법의 주요 개정 내용
- 데이터 3법
    - 개인정보보호법
    - 정보통신망 이용촉진 및 정보보호 등에 관한 법류(정보통신망법)
    - 신용정보의 이용 및 보호에 관한 법률(신용정보보호법)
- 데이터 이용 활성화를 위한 '가명정보'개념 도입 및 데이터간 결합 근거 마련
- 개인정보보호 관련 법률의 유사ㆍ중복 규정을 정비 및 거버넌스 체계 효율화
- 데이터 활용에 따른 개인정보처리자 책임 강화
- 다소 모호했던 개인정보의 판단기준 명확하

### 1. 개인정보보호법 주요 개정 내용
- 개인정보 관련 개념을 개인정보, 가명정보, 익명정보로 구분
- 가명정보를 통계 작성 연구, 공익적 기록보존 목적을 처리할 수 있도록 허용
- 가명정보 이용 시 안전장치 및 통제 수단 마련
- 분산된 개인정보보호 감독기관을 개인정보보호위원회로 일원화
- 개인정보보호위원회는 국무총리 소속 중앙행정기관으로 격상
### 2. 정보통신망법 주요 개정 내용
- 개인정보보호 관련 사항을 개인정보보호법으로 이관
- 온라인상 개인정보보호 관련 규제 및 감독 주체를 개인정보보호위원회로 변경
### 3. 신용정보보호법 주요 개정 내용
- 가명정보 개념을 도입해 빅데이터 분석 및 이용의 법적 근거 마련
- 가명정보는 통계 작성 연구, 공익적 기록보존 등을 위해 신용정보 주체의 동의 없이 이용, 제공 가능

## 5. 유럽 연합과 미국의 개인정보보호 체계
### 1. 유럽 연합(EU)
- 유럽 연합의 시민의 데이터를 활용하는 경우 GDPR을 준수해야 한다.
    - GDPR(General Data Protection Regulation)
        - 유럽 의회에서 유럽 시민들의 개인정보 보호를 강화하기 위해 만든 통합 규정
- GDPR은 정보주체의 권리와 기업의 책임성 강화 등을 주요 내용으로 하며 위반 시 과징금 부과를 규정하고 있다.
- GDPR의 주요 항목으로 사용자가 본인의 데이터 처리 관련 사항을 제공 받을 권리, 열람ㆍ정정ㆍ삭제 요청 권리, 데이터 이동 권리, 처리 거부 요청 권리 등이 있다.

### 2. 미국
- 미국은 기본적으로 시장 자율 규율(self-regulation) 방식으로 EU나 한국과 같이 공공 부문과 민간 부문을 포괄하는 개인정보보호에 관한 일반법이 연방법률로서 존재하지 않는다.
    - 대신 공공, 통신, 금융, 교육, 의료, 근로자 정보 등 영역별로 개인정보보호를 규율하는 개별 법률이 각 분야별 개인정보보호를 담당한다.
- 주 법체계에서는 EU의 GDPR 제정 이후 캘리포니아 주의 캘리포니아 소비자 개인정보보호법(California Consumer Privacy Act, CCPA)을 시작으로 많은 주들이 포괄적인 일반 개인정보보호법을 도입하려는 노력을 진행중이다.

# 6. 개인정보 비식별화
## 1. 개인정보 비식별화의 개요
### 1. 비식별 정보
- 정보의 집합물에 대해 '개인정보 비식별 조치 가이드라인'에 따라 적정하게 비식별 조치된 정보를 말한다.
### 2. 비식별 조치
- 정보의 집합물에게 개인을 식별할 수 있는 요소를 전부 또는 일부 삭제하거나 대체 등의 방법을 통해 개인을 알아볼 수 없도록 하는 조치를 말한다.
### 3. 비식별 정보의 활용
- 비식별 정보는 개인정보가 아닌 정보로 추정되므로 정보주체로부터의 별도 동의없이 해당 정보를 이용하거나 제3자에게 제공할 수 있다.
    - 다만, 불특정 다수에게 공개되는 경우에는 다른 정보를 보유하고 있는 누군가에 의해 해당 정보주체가 식별될 가능성이 있으므로 비식별 정보의 공개는 원칙적으로 금지된다.
### 4. 비식별 정보의 보호
- 비식별 정보는 개인정보가 아닌 것으로 추정되지만, 새로운 결합 기술이 나타나거나 결합 가능한 정보가 증가하는 경우 정보주체가 '재식별'될 가능성이 있다.
- 비식별 정보를 처리하는 자(비식별 정보를 제공받은 자 포함)가 해당 정보를 이용하는 과정에서 재식별하게 된 경우에는 해당 정보를 즉시 처리중지하고 파기하여야 한다.
- 비식별 정보라고 하더라도 필수적인 관리적ㆍ기술적 보호조치는 이행해야 한다.

## 2. 개인정보 비식별화 조치 가이드라인
데이터 이용 과정에서 개인정보 침해ㆍ방지를 위해 개인정보를 비식별 조치하는 절차 및 방법에 대한 가이드라인으로, 개인정보를 비식별 조치하여 이용 또는 제공하려는 사업자 등이 준수하여야 할 기준을 제시한다.
### 1. 개인정보 비식별화 조치 가이드라인의 추진배경
- 정부 3.0 및 빅데이터 활용 확산에 따른 데이터 활용가치가 증대되고 있다.
- 개인정보 보호 강화에 대한 사회적 요구가 지속되고 있다.
### 2. 개인정보 비식별화 조치 가이드라인의 단계별 조치사항
- 사전 검토
    - 조치사항: 개인정보에 해당하는지 여부를 검토한 후, 개인정보가 아닌 것이 명백한 경우 법적 규제 없이 자유롭게 활용
    - 데이터: 개인정보, 식별정보
- 비식별 조치
    - 조치사항: 정보 집합물(데이터셋)에서 개인을 식별할 수 있는 요소를 전부 또는 일부 삭제하거나 대체하는 등의 방법을 활용, 개인을 알아볼 수 없도록 하는 조치
    - 데이터: 가명, 총계, 삭제, 범주화, 마스킹
- 적정성 평가
    - 조치사항: 다른 정보와 쉽게 결합하여 개인을 식별할 수 있는지를 '비식별 조치 적정성 평가단'을 통해 평가
    - 데이터: k-익명성, l-다양성, t-근접성
- 사후 관리
    - 조치사항: 비식별 정보 안전조치, 재식별 가능성 모니터링 등 비식별 정보 활용 과정에서 재식별 방지를 위해 필요한 조치 수행
    - 데이터: 관리적/기술적 보호조치

### 3. 개인정보 비식별화 조치 가이드라인의 조치방법
- 가명 처리
    - 개인정보 중 주요식별 요소를 다른 값으로 대체하는 방법이다.
    - 값을 대체 시 규칙이 노출되어 역으로 쉽게 식별할 수 없도록 주의해야 한다.
- 총계 처리 
    - 데이터의 총합 값을 보여주고 개별 값을 보여주이 않는 방법이다.
    - 특정 속성을 지닌 개인으로 구성된 단체의 속성 정보를 공개하는 것은 그 집단에 속한 개인의 정보를 공개하는 것과 마찬가지이므로 주의해야 한다.
    - ex. 에이즈 환자 집단임을 공개하면서 특정인이 그 집단에 속함을 알 수 있도록 표시하는 행위 금지
- 데이터 삭제
    - 데이터 공유나 개방 목적에 따라 데이터 셋에 구성된 값 중 필요 없는 값 또는 개인식별에 중요한 값을 삭제하는 방법이다.
    - ex. 개인과 과련된 날짜정보(합격일 등)는 연단위로 처리
- 데이터 범주화
    - 데이터의 값을 범주의 값으로 변환하여 값을 숨기는 방법이다.
- 데이터 마스킹
    - 개인을 식별하는데 기여할 확률이 높은 주요 식별자를 보이지 않도록 처리하는 방법이다.
    - 남아 있는 정보만으로 개인을 식별할 수 없어야 하며, 공개된 다른 정보와 결합하더라도 특정 개인을 식별할 수 없어야 한다.

# 7. 가명정보 활용
## 1. 가명정보의 개요
### 1. 가명정보의 정의
- 활용하고자 하는 개인정보의 일부를 삭제하거나 일부 또는 전부를 대체하는 등의 방법으로 처리하는 과정을 가명처리라 하며, 이 산출물을 가명정보라 한다.
- 데이터 3법에서는 데이터 이용 활성화를 위해 가명정보 개념을 도입했으며, 개인정보 및 익명정보와 비교하면 다음과 같다.
    - 개인정보
        - 특정 개인에 대한 정보
        - 특정 개인을 알아볼 수 있게 하는 정보
        - 정보주체로부터 사전에 개인정보 활용에 대한 구체적인 동의를 받은 범위 내에서 활용 가능
    - 가명정보
        - 추가 정보 없이는 특정 개인을 알아볼 수 없는 정보
        - 사전에 동의 없이 통계작성(상업적 목적 포함), 과학적 연구(산업적 연구 포함), 공익적 기록 보존 목적 등으로 활용 가능
    - 익명정보
        - 특정 개인을 알아볼 수 없도록 처리한 정보
        - 개인정보가 아니기에 제약 없이 활용 가능
### 2. 가명처리의 필요성
- 개인정보는 특정 개인에 대한 다양한 정보들이 포함되어 있는 관계로 이를 처리 및 활용하는 과정에서 특정 개인의 사생활 침해 등 여러 문제가 발생할 수 있다.
- 개인정보를 안전하게 활용하기 위해 특정 개인에 대한 정보들이 노출되어 식별되지 않도록 기술적인 조치를 수행하여야 한다.
### 3. 가명처리의 목적 및 대상
- 가명정보는 통계작성, 과학적 연구, 공익적 기록 보존 등의 목적으로 개인정보 처리자의 정당한 처리 범위 내에서 정보주체의 사전 동의 없이 처리할 수 있다.
    - 통계작성
        - 통계는 특정 집단이나 대상 등에 대하여 작성한 수치 정보
        - 시장조사와 같은 상업적 목적의 통계처리도 가능
        - CRM(Customer Relationship Management) 목적으로 개인에 대한 식별이 필요 또는 가능한 경우 제외
    - 과학적 연구
        - 기술의 개발과 실증, 기초연구, 응용 연구 및 민간 투자 연구 등 과학적 방법을 적용하는 연구
    - 공익적 기록 보존
        - 공공의 이익을 위하여 지속적으로 열람할 가치가 있는 정보를 기록하여 보존
        - 민간 기업이나 단체 등이 일반적인 공익을 위하여 기록을 보존하는 경우도 가능

## 2. 가명처리 절차
가명정보 처리자가 가명처리한 결과, 목적을 달성하기 어렵거나 재식별 가능성이 있는 경우 가명처리(3단계)를 반복하거나 부분적으로 가명처리를 추가 수행할 수 있다.
- 목적 설정 등 사전준비, 위험성 검토, 가명처리, 적정성 검토, 안전한 관리의 총 5단계로 구성되어 있다.
1. 목적 설정 등 사전준비
    - 가명정보 처리 목적을 명확하게 설정한다.
    - 가명정보 처리 목적의 적합성을 검토한다.
    - 계약서나 개인정보 처리지침 또는 내부 관리계획 등 필요한 서류들을 작성한다.
2. 위험성 검토
    - 대상 선정
        - 목적을 달성하기 위하여 필요한 항목을 개인정보 파일에서 선정
        - 가명정보 처리 목적달성에 필요한 최소한의 항목으로 선정 필요
    - 위험성 검토
        - 가명처리 대상 데이터의 식별 위험성을 분석 및 평가
        - 가명처리 방법 및 수준 설정 시 반영
3. 가명처리
    - 항목별 가명처리 방법과 수준을 먼저 정의하고, 이에 맞게 가명처리를 수행한다.
    - 식별자와 준신별자에 대한 비식별화를 수행한다.
4. 적정성 검토
    - 가명처리가 적정하게 수행되었는지 확인한다.
    - 가명처리 결과가 가명정보의 처리 목적에 부합한지 검토한다.
    - 필요서류, 처리 목적 정합성, 식별 위험성, 가명처리 방법 및 수준의 적정성, 가명처리의 적정성, 처리 목적 달성 가능성 단계로 검토를 수행한다.
    - 프라이버시 기반 추론방지 모델을 이용하여 재식별 가능성을 식별한다.
5. 안전한 관리
    - 생성된 가명정보를 법령에 따라 물리적, 관리적, 기술적 안전조치 등 사후관리를 이행한다.(재식별 가능성 모니터링)

# 8. 개인정보 활용
## 1. 데이터 수집의 위기 요인과 통제 방안
### 1. 사생활 침해로 위기 발생
- M2M(Machine to Machine) 시대가 되면서 정보를 수집하는 센서들의 수가 증가하고 있다.
- 개인정보의 가치가 커짐에 따라 많은 사업자들이 개인정보 습득에 더 많은 자원을 투입하고 있다.
- 특정 데이터가 본래 목적 외로 가공되어 2차, 3차 목적으로 활용될 가능성이 커지고 있다.
- 위험의 범위가 사생활 침해 수준을 넘어 사회, 경제적 위협으로 더 확대될 수 있다.
### 2. 동의에서 책임으로 강화하여 통제
- 개인정보는 본래 1차적 목적 외에도 2차, 3차적 목적으로 가공, 유통, 활용되고 있다.
    - 개인정보의 활용에 대해 개인이 매번 동의하는 것은 매우 어려운 일이며, 경제적으로도 비효율적이다.
- 개인정보 사용으로 발생하는 피해에 대해서는 개인정보 사용자가 책임을 지게 한다.
- 개인정보를 사용하는 주체가 익명화 기술 같은 더 적극적인 보호 장치를 마련하게 하는 효과가 있을 것으로 기대된다.

## 2. 데이터 활용의 위기요인과 통제 방안
### 1. 책임원칙 훼손으로 위기 발생
- 빅데이터의 분석 결과에 따라 특정한 행위를 할 가능성이 높다는 이유만으로 특정인이 처벌받는 것은 민주주의 사회 원칙을 훼손한다.
- 특정인이 특성한 사회, 경제적 특성을 가진 집단에 속한다는 이유만으로 그의 신용도와 무관하게 대출이 거절되는 상황은 잘못된 클러스터링의 피해이다.
- 특정 조건을 가진 학생이 대학에 진학하고자 할 때 잘못된 예측 알고리즘에 의해 진학할 기회 자체를 주지 않는다면 이는 사회 정의 문제와도 직결된다.
### 2. 결과 기반 책임 원칙을 고수하여 통제
- 기존의 책임 원칙을 더욱 강화해야 한다.
- 예측 결과에 의해 불이익을 당할 가능성을 최소화하는 방안 마련이 필요하다.
- 제도 마련과 함께 알고리즘의 기술적 완성도를 더 높여야 한다.

## 3. 데이터 처리의 위기요인과 통제 방안
### 1. 데이터 오용으로 위기 발생
- 빅데이터는 과게에 일어났던 일로 인해 기록된 데이터에 의존한다.
    - 빅데이터를 기반으로 미래를 예측하는 것은 어느정도 정확도를 가질 수 있지만 항상 맞는 것은 아니다.
- 빅데이터 사용자가 데이터를 과신할 때 큰 문제가 발생할 가능성이 높다.
    - 잘못된 지표를 사용하는 것은 오히려 과거 경험에 의존하는 것보다 더 잘못된 결론을 도출 할 수 있다.
### 2. 알고리즘 접근을 허용하여 통제
- 알고리즘에 대한 접근권한을 부여받아 직접 검증할 수 있도록 한다.
- 알고리즘에 대한 객곽적인 인증방안을 마련 및 도입한다.
- 알고리즘의 부당함을 반증할 수 있는 방법을 제시해 줄 것을 요청한다.
- 공개해 준 알고리즘을 해석해 줄 알고리즈미스트와 같은 전문가를 요청한다.
    - 알고리즈미스트는 만들어진 알고리즘을 분석하여 해당 알고리즘으로 부당한 피해를 보는 사람을 구제하는 역할을 수행할 수 있다.
    - 알고리즈미스트는 컴퓨터, 수학, 통계학, 비즈니스 등의 다양한 지식이 필요하다.